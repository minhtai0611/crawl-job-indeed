{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from selenium.webdriver.common.by import By\n",
    "import undetected_chromedriver as uc\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "import time\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from lxml import etree\n",
    "import pendulum\n",
    "import operator as op\n",
    "\n",
    "driver = uc.Chrome()\n",
    "time.sleep(3)\n",
    "driver.get('https://www.indeed.com/')\n",
    "time.sleep(6)"
   ],
   "id": "1895e1df3beea50b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "keyword_filter= \"data analyst\"\n",
    "location_filter = \"vietnam\"\n",
    "page_count_filter = \"5\"\n",
    "salary_filter = \"126920 VNƒê hour\"\n",
    "start_date_posted_filter = \"2024-07-01 00:00:00\"\n",
    "end_date_posted_filter = \"2025-01-31 23:59:59\"\n",
    "time.sleep(3)"
   ],
   "id": "cb0048cd60031f83",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "search_job_keyword = driver.find_element(By.XPATH, '//input[@aria-label=\"search: Job title, keywords, or company\"]')\n",
    "time.sleep(3)\n",
    "search_job_keyword.click()\n",
    "time.sleep(3)\n",
    "search_job_keyword.send_keys(keyword_filter)\n",
    "time.sleep(3)\n",
    "search_location_keyword = driver.find_element(By.XPATH, '//input[@aria-label=\"Edit location\"]')\n",
    "time.sleep(3)\n",
    "search_location_keyword.click()\n",
    "time.sleep(3)\n",
    "search_location_keyword.send_keys(location_filter)\n",
    "time.sleep(3)\n",
    "search_button = driver.find_element(By.XPATH, '//button[@class=\"yosegi-InlineWhatWhere-primaryButton\"]')\n",
    "time.sleep(3)\n",
    "search_button.submit()\n",
    "time.sleep(6)"
   ],
   "id": "5511873664ac22b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def search_job_indeed():\n",
    "    global search_job_indeed_list, search_job_indeed_final_list, search_job_indeed_final_list_filter\n",
    "    search_job_indeed_final_list = []\n",
    "    time.sleep(3)\n",
    "    while True:\n",
    "        try:\n",
    "            job_indeed_frame = driver.find_elements(By.XPATH, '//div[@id=\"mosaic-provider-jobcards\"]/ul/li/div/div/div/div/div/div/table/tbody/tr/td[1]/div[1]/h2/a')\n",
    "            time.sleep(3)\n",
    "            search_job_indeed_list = list(set((job_indeed.get_attribute('href') for job_indeed in job_indeed_frame)))\n",
    "            time.sleep(3)\n",
    "            job_indeed_frame[-1].location_once_scrolled_into_view\n",
    "            time.sleep(6)\n",
    "        except:\n",
    "            print('No more job')\n",
    "            time.sleep(3)\n",
    "        search_job_indeed_final_list.extend(search_job_indeed_list)\n",
    "        time.sleep(3)\n",
    "        search_job_indeed_final_list = list(set(search_job_indeed_final_list))\n",
    "        time.sleep(3)\n",
    "        if (len(search_job_indeed_final_list) % 15 == 0 and len(search_job_indeed_final_list) // 15 == int(page_count_filter)) or (len(search_job_indeed_final_list) % 15 != 0 and len(search_job_indeed_final_list) // 15 + 1 == int(page_count_filter)):\n",
    "            break\n",
    "        try:\n",
    "            next_page_button = driver.find_elements(By.XPATH, '//nav[@aria-label=\"pagination\"]/ul/li/a')\n",
    "            time.sleep(3)\n",
    "            next_page_button[-1].click()\n",
    "            time.sleep(3)\n",
    "            yield len(search_job_indeed_final_list)\n",
    "        except:\n",
    "            print('No more page')\n",
    "            time.sleep(3)\n",
    "            break\n",
    "\n",
    "generators = search_job_indeed()\n",
    "for generator in generators:\n",
    "    print(generator)"
   ],
   "id": "4d156931d1bc2105",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if len(search_job_indeed_final_list) % 15 == 0:\n",
    "    if len(search_job_indeed_final_list) == 0:\n",
    "        search_job_indeed_final_list_filter = []\n",
    "    elif len(search_job_indeed_final_list) // 15 + 1 < int(page_count_filter):\n",
    "        search_job_indeed_final_list_filter = search_job_indeed_final_list\n",
    "    else:\n",
    "        search_job_indeed_final_list_filter = search_job_indeed_final_list[:int(page_count_filter) * 15]\n",
    "else:\n",
    "    if len(search_job_indeed_final_list) // 15 + 1 < int(page_count_filter):\n",
    "        search_job_indeed_final_list_filter = search_job_indeed_final_list\n",
    "    elif len(search_job_indeed_final_list) // 15 + 1 == int(page_count_filter):\n",
    "        search_job_indeed_final_list_filter = search_job_indeed_final_list[:(int(page_count_filter) - 1) * 15 + len(search_job_indeed_final_list) % 15]\n",
    "    else:\n",
    "        search_job_indeed_final_list_filter = search_job_indeed_final_list[:int(page_count_filter) * 15]"
   ],
   "id": "85b31fcd93816fea",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "len(search_job_indeed_final_list_filter)",
   "id": "cac9fb6ed5828a3d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_job_indeed_description():\n",
    "        global job_indeed_description_list\n",
    "        job_indeed_description_list = []\n",
    "        for _, job_indeed_url in enumerate(search_job_indeed_final_list_filter):\n",
    "            driver.get(job_indeed_url)\n",
    "            time.sleep(6)\n",
    "            try:\n",
    "                    company = driver.find_element(By.XPATH, '//div[@data-testid=\"jobsearch-CompanyInfoContainer\"]/div/div/div/div/div[1]/span/a').text\n",
    "                    time.sleep(3)\n",
    "                    sub_company = driver.find_element(By.XPATH, '//div[@data-testid=\"jobsearch-CompanyInfoContainer\"]/div/div/div/div/div[2]/span').text\n",
    "                    time.sleep(3)\n",
    "                    if len(re.findall(r'\\b\\d+\\.\\d+\\b', sub_company)) > 0:\n",
    "                        total_company = company\n",
    "                    else:\n",
    "                        total_company = company + ' ' + sub_company\n",
    "                    time.sleep(3)\n",
    "            except:\n",
    "                    try:\n",
    "                            time.sleep(3)\n",
    "                            total_company = driver.find_element(By.XPATH, '//div[@data-testid=\"jobsearch-CompanyInfoContainer\"]/div/div/div/div/div[1]/span/a').text\n",
    "                            time.sleep(3)\n",
    "                    except:\n",
    "                            try:\n",
    "                                    time.sleep(3)\n",
    "                                    total_company = driver.find_element(By.XPATH, '//div[@data-testid=\"jobsearch-CompanyInfoContainer\"]/div/div/div/div/div[1]/span').text\n",
    "                                    time.sleep(3)\n",
    "                            except:\n",
    "                                    try:\n",
    "                                            time.sleep(3)\n",
    "                                            total_company = driver.find_element(By.XPATH, '//div[starts-with(@class, \"jobsearch-InfoHeaderContainer\")]/div/div/h2').text\n",
    "                                            time.sleep(3)\n",
    "                                    except:\n",
    "                                            try:\n",
    "                                                    time.sleep(3)\n",
    "                                                    total_company = driver.find_element(By.XPATH, '//div[starts-with(@class, \"jobsearch-InfoHeaderContainer\")]/div/div/h2').text\n",
    "                                                    time.sleep(3)\n",
    "                                            except:\n",
    "                                                    time.sleep(3)\n",
    "                                                    total_company = ''\n",
    "                                                    time.sleep(3)\n",
    "            try:\n",
    "                    header = driver.find_element(By.XPATH, '//div[starts-with(@class,\"jobsearch-JobInfoHeader-title-container\")]/h1/span').text\n",
    "                    time.sleep(3)\n",
    "            except:\n",
    "                    try:\n",
    "                            time.sleep(3)\n",
    "                            header = driver.find_element(By.XPATH, '//div[starts-with(@class, \"jobsearch-InfoHeaderContainer\")]/div/div/div/span').text\n",
    "                            time.sleep(3)\n",
    "                    except:\n",
    "                            time.sleep(3)\n",
    "                            header = ''\n",
    "                            time.sleep(3)\n",
    "            try:\n",
    "                    location = driver.find_element(By.XPATH, '//div[@data-testid=\"jobsearch-CompanyInfoContainer\"]/div/div/div/div[2]/div').text\n",
    "                    time.sleep(3)\n",
    "            except:\n",
    "                    try:\n",
    "                            time.sleep(3)\n",
    "                            location = driver.find_element(By.XPATH, '//div[starts-with(@class, \"jobsearch-InfoHeaderContainer\")]/div/div/div/div[2]/div').text\n",
    "                            time.sleep(3)\n",
    "                    except:\n",
    "                            try:\n",
    "                                time.sleep(3)\n",
    "                                location = driver.find_element(By.XPATH, '//div[starts-with(@class, \"jobsearch-InfoHeaderContainer\")]/div/div[2]/div/div/div/div[2]/div').text\n",
    "                                time.sleep(3)\n",
    "                            except:\n",
    "                                    time.sleep(3)\n",
    "                                    location = ''\n",
    "                                    time.sleep(3)\n",
    "            try:\n",
    "                soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "                time.sleep(3)\n",
    "                script_context = soup.find_all('script', string=re.compile(r'@context'))[0].getText().strip()\n",
    "                time.sleep(3)\n",
    "                standard_date_posted = re.search(r'\\\"datePosted\\\":\\\"([^\"]+)\\\"', script_context).group(1)\n",
    "                time.sleep(3)\n",
    "                readable_date_posted = pendulum.parse(standard_date_posted, tz='Asia/Ho_Chi_Minh').to_datetime_string()\n",
    "                time.sleep(3)\n",
    "            except:\n",
    "                try:\n",
    "                    soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "                    time.sleep(3)\n",
    "                    script_initial_data = soup.find_all('script', string=re.compile(r'window._initialData'))[0].getText().strip()\n",
    "                    time.sleep(3)\n",
    "                    standard_date_posted = re.search(r'\\\"datePublished\\\":(\\d+)', script_initial_data).group(1)\n",
    "                    time.sleep(3)\n",
    "                    readable_date_posted = pendulum.from_timestamp(int(standard_date_posted) / 1000, tz='Asia/Ho_Chi_Minh').to_datetime_string()\n",
    "                    time.sleep(3)\n",
    "                except:\n",
    "                        time.sleep(3)\n",
    "                        readable_date_posted = ''\n",
    "                        time.sleep(3)\n",
    "            try:\n",
    "                soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "                time.sleep(3)\n",
    "                script_initial_data = soup.find_all('script', string=re.compile(r'window._initialData'))[0].getText().strip()\n",
    "                time.sleep(3)\n",
    "                salary = re.search(r'\\\"salaryText\\\":\\\"([^\"]+)\\\"', script_initial_data).group(1)\n",
    "                time.sleep(3)\n",
    "            except:\n",
    "                    time.sleep(3)\n",
    "                    salary = ''\n",
    "                    time.sleep(3)\n",
    "            job_indeed_description_list.append((job_indeed_url, total_company, header, salary, location, readable_date_posted))\n",
    "            yield total_company, header, location, readable_date_posted, salary\n",
    "generators = get_job_indeed_description()\n",
    "for generator in generators:\n",
    "    print(generator)"
   ],
   "id": "a5ee7a0298e367d6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "len(job_indeed_description_list)",
   "id": "a4390f179d839de4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "from google.oauth2 import service_account\n",
    "import pandas as pd\n",
    "\n",
    "credentials = service_account.Credentials.from_service_account_file('credentials.json')\n",
    "spreadsheet_service = build('sheets', 'v4', credentials=credentials)\n",
    "\n",
    "SPREADSHEET_ID = '1F75bELM8_nYQvFBVqReVUZYcPGuuELIa4nh9MJoS9Tg'\n",
    "RANGE_NAME = 'Sheet1'\n",
    "sheet = spreadsheet_service.spreadsheets()\n",
    "result = sheet.values().get(spreadsheetId=SPREADSHEET_ID, range=RANGE_NAME).execute()\n",
    "values = result.get('values', [])\n",
    "max_cols = max(len(row) for row in values)\n",
    "values = [row + [''] * (max_cols - len(row)) for row in values]\n",
    "df = pd.DataFrame(values[1:], columns=values[0])\n",
    "df = df.fillna('')"
   ],
   "id": "aab379cf81ef9b1b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df1 = pd.DataFrame(job_indeed_description_list, columns=df.columns).__deepcopy__()\n",
    "df1"
   ],
   "id": "982272decfbf3da0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def implement_salary_filter():\n",
    "    global implement_filter_list\n",
    "    implement_filter_list = []\n",
    "    salary_filter_tuple = (salary_filter.split(' ')[0], salary_filter.split(' ')[1], salary_filter.split(' ')[2])\n",
    "    for index, row in df1.iterrows():\n",
    "        if op.contains(df1.at[index, 'Salary'], salary_filter_tuple[1]) and op.contains(df1.at[index, 'Salary'], salary_filter_tuple[2]):\n",
    "            range_salary_tuple = tuple(int(salary.replace(',', '')) for salary in re.findall(r\"([\\d,]+)\", df1.iloc[index]['Salary']))\n",
    "            print(range_salary_tuple)\n",
    "            if len(range_salary_tuple) == 2 and (int(salary_filter_tuple[0]) >= range_salary_tuple[0] and int(salary_filter_tuple[0]) <= range_salary_tuple[1]):\n",
    "                implement_filter_list.append((row[df1.columns[0]], row[df1.columns[1]], row[df1.columns[2]], row[df1.columns[3]], row[df1.columns[4]], row[df1.columns[5]]))\n",
    "                yield from implement_filter_list\n",
    "            elif len(range_salary_tuple) == 1 and (int(salary_filter_tuple[0]) <= range_salary_tuple[0] and op.contains(df1.iloc[index]['Salary'].lower(), 'up to')):\n",
    "                implement_filter_list.append((row[df1.columns[0]], row[df1.columns[1]], row[df1.columns[2]], row[df1.columns[3]], row[df1.columns[4]], row[df1.columns[5]]))\n",
    "                yield from implement_filter_list\n",
    "            elif len(range_salary_tuple) == 1 and (int(salary_filter_tuple[0]) >= range_salary_tuple[0] and op.contains(df1.iloc[index]['Salary'].lower(), 'from')):\n",
    "                implement_filter_list.append((row[df1.columns[0]], row[df1.columns[1]], row[df1.columns[2]], row[df1.columns[3]], row[df1.columns[4]], row[df1.columns[5]]))\n",
    "                yield from implement_filter_list\n",
    "            elif len(range_salary_tuple) == 1 and (int(salary_filter_tuple[0]) == range_salary_tuple[0] and (not op.contains(df1.iloc[index]['Salary'].lower(), 'up to') and not op.contains(df1.iloc[index]['Salary'].lower(), 'from'))):\n",
    "                implement_filter_list.append((row[df1.columns[0]], row[df1.columns[1]], row[df1.columns[2]], row[df1.columns[3]], row[df1.columns[4]], row[df1.columns[5]]))\n",
    "                yield from implement_filter_list\n",
    "salary_generators = implement_salary_filter()\n",
    "for generator in salary_generators:\n",
    "    print(generator)"
   ],
   "id": "2caa9b6698ede848",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df2 = pd.DataFrame(implement_filter_list, columns=df1.columns).__deepcopy__()\n",
    "implement_filter_list = []"
   ],
   "id": "cfceb9999ab79def",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def implement_date_posted_filter():\n",
    "    for row in df2.itertuples(index=False):\n",
    "        if pendulum.parse(start_date_posted_filter, tz='Asia/Ho_Chi_Minh') <= pendulum.parse(row._5, tz='Asia/Ho_Chi_Minh') and pendulum.parse(end_date_posted_filter, tz='Asia/Ho_Chi_Minh') >= pendulum.parse(row._5, tz='Asia/Ho_Chi_Minh'):\n",
    "            implement_filter_list.append((row.Link, row.Company, row.Title, row.Salary, row.Location, row._5))\n",
    "            yield from implement_filter_list\n",
    "date_posted_generators = implement_date_posted_filter()\n",
    "for generator in date_posted_generators:\n",
    "    print(generator)\n",
    "implement_filter_list = list(set(implement_filter_list))"
   ],
   "id": "2fff39bfbad0d0c1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df3 = pd.DataFrame(implement_filter_list, columns=df1.columns).__deepcopy__()\n",
    "updated_values = [df3.columns.tolist()] + df3.values.tolist()\n",
    "body = {'values': updated_values}\n",
    "spreadsheet_service.spreadsheets().values().update(\n",
    "    spreadsheetId=SPREADSHEET_ID, range=RANGE_NAME,\n",
    "    valueInputOption='RAW', body=body).execute()"
   ],
   "id": "ae3b56ab3a152dad",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
