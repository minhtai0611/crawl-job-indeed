{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T02:46:46.746148Z",
     "start_time": "2025-01-10T02:46:27.101744Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from selenium.webdriver.common.by import By\n",
    "import undetected_chromedriver as uc\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "import time\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from lxml import etree\n",
    "import pendulum\n",
    "import operator as op\n",
    "\n",
    "driver = uc.Chrome()\n",
    "time.sleep(3)\n",
    "driver.get('https://www.indeed.com/')\n",
    "time.sleep(6)"
   ],
   "id": "1895e1df3beea50b",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T02:46:49.850508Z",
     "start_time": "2025-01-10T02:46:46.839275Z"
    }
   },
   "cell_type": "code",
   "source": [
    "keyword_filter= \"data analyst\"\n",
    "location_filter = \"vietnam\"\n",
    "page_count_filter = \"1\"\n",
    "salary_filter = \"126920 VNƒê hour\"\n",
    "start_date_posted_filter = \"2024-07-01 00:00:00\"\n",
    "end_date_posted_filter = \"2025-01-31 23:59:59\"\n",
    "time.sleep(3)"
   ],
   "id": "cb0048cd60031f83",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T02:47:19.906302Z",
     "start_time": "2025-01-10T02:46:49.859505Z"
    }
   },
   "cell_type": "code",
   "source": [
    "search_job_keyword = driver.find_element(By.XPATH, '//input[@aria-label=\"search: Job title, keywords, or company\"]')\n",
    "time.sleep(3)\n",
    "search_job_keyword.click()\n",
    "time.sleep(3)\n",
    "search_job_keyword.send_keys(keyword_filter)\n",
    "time.sleep(3)\n",
    "search_location_keyword = driver.find_element(By.XPATH, '//input[@aria-label=\"Edit location\"]')\n",
    "time.sleep(3)\n",
    "search_location_keyword.click()\n",
    "time.sleep(3)\n",
    "search_location_keyword.send_keys(location_filter)\n",
    "time.sleep(3)\n",
    "search_button = driver.find_element(By.XPATH, '//button[@class=\"yosegi-InlineWhatWhere-primaryButton\"]')\n",
    "time.sleep(3)\n",
    "search_button.submit()\n",
    "time.sleep(6)"
   ],
   "id": "5511873664ac22b",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T02:47:41.167336Z",
     "start_time": "2025-01-10T02:47:19.928984Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def search_job_indeed():\n",
    "    global search_job_indeed_list, search_job_indeed_final_list, search_job_indeed_final_list_filter\n",
    "    search_job_indeed_final_list = []\n",
    "    time.sleep(3)\n",
    "    while True:\n",
    "        try:\n",
    "            job_indeed_frame = driver.find_elements(By.XPATH, '//div[@id=\"mosaic-provider-jobcards\"]/ul/li/div/div/div/div/div/div/table/tbody/tr/td[1]/div[1]/h2/a')\n",
    "            time.sleep(3)\n",
    "            search_job_indeed_list = list(set((job_indeed.get_attribute('href') for job_indeed in job_indeed_frame)))\n",
    "            time.sleep(3)\n",
    "            job_indeed_frame[-1].location_once_scrolled_into_view\n",
    "            time.sleep(6)\n",
    "        except:\n",
    "            print('No more job')\n",
    "            time.sleep(3)\n",
    "        search_job_indeed_final_list.extend(search_job_indeed_list)\n",
    "        time.sleep(3)\n",
    "        search_job_indeed_final_list = list(set(search_job_indeed_final_list))\n",
    "        time.sleep(3)\n",
    "        if (len(search_job_indeed_final_list) % 15 == 0 and len(search_job_indeed_final_list) // 15 == int(page_count_filter)) or (len(search_job_indeed_final_list) % 15 != 0 and len(search_job_indeed_final_list) // 15 + 1 == int(page_count_filter)):\n",
    "            break\n",
    "        try:\n",
    "            next_page_button = driver.find_elements(By.XPATH, '//nav[@aria-label=\"pagination\"]/ul/li/a')\n",
    "            time.sleep(3)\n",
    "            next_page_button[-1].click()\n",
    "            time.sleep(3)\n",
    "            yield len(search_job_indeed_final_list)\n",
    "        except:\n",
    "            print('No more page')\n",
    "            time.sleep(3)\n",
    "            break\n",
    "\n",
    "generators = search_job_indeed()\n",
    "for generator in generators:\n",
    "    print(generator)"
   ],
   "id": "4d156931d1bc2105",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T02:47:41.184376Z",
     "start_time": "2025-01-10T02:47:41.179410Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if len(search_job_indeed_final_list) % 15 == 0:\n",
    "    if len(search_job_indeed_final_list) == 0:\n",
    "        search_job_indeed_final_list_filter = []\n",
    "    elif len(search_job_indeed_final_list) // 15 + 1 < int(page_count_filter):\n",
    "        search_job_indeed_final_list_filter = search_job_indeed_final_list\n",
    "    else:\n",
    "        search_job_indeed_final_list_filter = search_job_indeed_final_list[:int(page_count_filter) * 15]\n",
    "else:\n",
    "    if len(search_job_indeed_final_list) // 15 + 1 < int(page_count_filter):\n",
    "        search_job_indeed_final_list_filter = search_job_indeed_final_list\n",
    "    elif len(search_job_indeed_final_list) // 15 + 1 == int(page_count_filter):\n",
    "        search_job_indeed_final_list_filter = search_job_indeed_final_list[:(int(page_count_filter) - 1) * 15 + len(search_job_indeed_final_list) % 15]\n",
    "    else:\n",
    "        search_job_indeed_final_list_filter = search_job_indeed_final_list[:int(page_count_filter) * 15]"
   ],
   "id": "85b31fcd93816fea",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T02:47:41.219351Z",
     "start_time": "2025-01-10T02:47:41.213435Z"
    }
   },
   "cell_type": "code",
   "source": "len(search_job_indeed_final_list_filter)",
   "id": "cac9fb6ed5828a3d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T02:59:12.163858Z",
     "start_time": "2025-01-10T02:47:41.232396Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_job_indeed_description():\n",
    "        global job_indeed_description_list\n",
    "        job_indeed_description_list = []\n",
    "        for _, job_indeed_url in enumerate(search_job_indeed_final_list_filter):\n",
    "            driver.get(job_indeed_url)\n",
    "            time.sleep(6)\n",
    "            try:\n",
    "                    company = driver.find_element(By.XPATH, '//div[@data-testid=\"jobsearch-CompanyInfoContainer\"]/div/div/div/div/div[1]/span/a').text\n",
    "                    time.sleep(3)\n",
    "                    sub_company = driver.find_element(By.XPATH, '//div[@data-testid=\"jobsearch-CompanyInfoContainer\"]/div/div/div/div/div[2]/span').text\n",
    "                    time.sleep(3)\n",
    "                    if len(re.findall(r'\\b\\d+\\.\\d+\\b', sub_company)) > 0:\n",
    "                        total_company = company\n",
    "                    else:\n",
    "                        total_company = company + ' ' + sub_company\n",
    "                    time.sleep(3)\n",
    "            except:\n",
    "                    try:\n",
    "                            time.sleep(3)\n",
    "                            total_company = driver.find_element(By.XPATH, '//div[@data-testid=\"jobsearch-CompanyInfoContainer\"]/div/div/div/div/div[1]/span/a').text\n",
    "                            time.sleep(3)\n",
    "                    except:\n",
    "                            try:\n",
    "                                    time.sleep(3)\n",
    "                                    total_company = driver.find_element(By.XPATH, '//div[@data-testid=\"jobsearch-CompanyInfoContainer\"]/div/div/div/div/div[1]/span').text\n",
    "                                    time.sleep(3)\n",
    "                            except:\n",
    "                                    try:\n",
    "                                            time.sleep(3)\n",
    "                                            total_company = driver.find_element(By.XPATH, '//div[starts-with(@class, \"jobsearch-InfoHeaderContainer\")]/div/div/h2').text\n",
    "                                            time.sleep(3)\n",
    "                                    except:\n",
    "                                            try:\n",
    "                                                    time.sleep(3)\n",
    "                                                    total_company = driver.find_element(By.XPATH, '//div[starts-with(@class, \"jobsearch-InfoHeaderContainer\")]/div/div/h2').text\n",
    "                                                    time.sleep(3)\n",
    "                                            except:\n",
    "                                                    time.sleep(3)\n",
    "                                                    total_company = ''\n",
    "                                                    time.sleep(3)\n",
    "            try:\n",
    "                    header = driver.find_element(By.XPATH, '//div[starts-with(@class,\"jobsearch-JobInfoHeader-title-container\")]/h1/span').text\n",
    "                    time.sleep(3)\n",
    "            except:\n",
    "                    try:\n",
    "                            time.sleep(3)\n",
    "                            header = driver.find_element(By.XPATH, '//div[starts-with(@class, \"jobsearch-InfoHeaderContainer\")]/div/div/div/span').text\n",
    "                            time.sleep(3)\n",
    "                    except:\n",
    "                            time.sleep(3)\n",
    "                            header = ''\n",
    "                            time.sleep(3)\n",
    "            try:\n",
    "                    location = driver.find_element(By.XPATH, '//div[@data-testid=\"jobsearch-CompanyInfoContainer\"]/div/div/div/div[2]/div').text\n",
    "                    time.sleep(3)\n",
    "            except:\n",
    "                    try:\n",
    "                            time.sleep(3)\n",
    "                            location = driver.find_element(By.XPATH, '//div[starts-with(@class, \"jobsearch-InfoHeaderContainer\")]/div/div/div/div[2]/div').text\n",
    "                            time.sleep(3)\n",
    "                    except:\n",
    "                            try:\n",
    "                                time.sleep(3)\n",
    "                                location = driver.find_element(By.XPATH, '//div[starts-with(@class, \"jobsearch-InfoHeaderContainer\")]/div/div[2]/div/div/div/div[2]/div').text\n",
    "                                time.sleep(3)\n",
    "                            except:\n",
    "                                    time.sleep(3)\n",
    "                                    location = ''\n",
    "                                    time.sleep(3)\n",
    "            try:\n",
    "                soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "                time.sleep(3)\n",
    "                script_context = soup.find_all('script', string=re.compile(r'@context'))[0].getText().strip()\n",
    "                time.sleep(3)\n",
    "                standard_date_posted = re.search(r'\\\"datePosted\\\":\\\"([^\"]+)\\\"', script_context).group(1)\n",
    "                time.sleep(3)\n",
    "                readable_date_posted = pendulum.parse(standard_date_posted, tz='Asia/Ho_Chi_Minh').to_datetime_string()\n",
    "                time.sleep(3)\n",
    "            except:\n",
    "                try:\n",
    "                    soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "                    time.sleep(3)\n",
    "                    script_initial_data = soup.find_all('script', string=re.compile(r'window._initialData'))[0].getText().strip()\n",
    "                    time.sleep(3)\n",
    "                    standard_date_posted = re.search(r'\\\"datePublished\\\":(\\d+)', script_initial_data).group(1)\n",
    "                    time.sleep(3)\n",
    "                    readable_date_posted = pendulum.from_timestamp(int(standard_date_posted) / 1000, tz='Asia/Ho_Chi_Minh').to_datetime_string()\n",
    "                    time.sleep(3)\n",
    "                except:\n",
    "                        time.sleep(3)\n",
    "                        readable_date_posted = ''\n",
    "                        time.sleep(3)\n",
    "            try:\n",
    "                soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "                time.sleep(3)\n",
    "                script_initial_data = soup.find_all('script', string=re.compile(r'window._initialData'))[0].getText().strip()\n",
    "                time.sleep(3)\n",
    "                salary = re.search(r'\\\"salaryText\\\":\\\"([^\"]+)\\\"', script_initial_data).group(1)\n",
    "                time.sleep(3)\n",
    "            except:\n",
    "                    time.sleep(3)\n",
    "                    salary = ''\n",
    "                    time.sleep(3)\n",
    "            job_indeed_description_list.append((job_indeed_url, total_company, header, salary, location, readable_date_posted))\n",
    "            yield total_company, header, location, readable_date_posted, salary\n",
    "generators = get_job_indeed_description()\n",
    "for generator in generators:\n",
    "    print(generator)"
   ],
   "id": "a5ee7a0298e367d6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('RMIT University', 'Research and Data Analyst (short-term & contracted through 3rd party)', 'Th√†nh ph·ªë H·ªì Ch√≠ Minh', '2025-01-08 15:36:07', '')\n",
      "('Bosch Group', '[SO] Senior Data Analyst', 'Th√†nh ph·ªë H·ªì Ch√≠ Minh', '2025-01-08 03:27:59', '')\n",
      "('VeXeRe', 'HCM ‚Äì Data Analyst Intern', 'Th√†nh ph·ªë H·ªì Ch√≠ Minh', '2024-11-26 17:12:47', '')\n",
      "('LARION Consulting & Software Development Joint Stock Company', 'Business Analyst Intern', 'Th√†nh ph·ªë H·ªì Ch√≠ Minh', '2024-11-14 07:28:53', '1,000,000 VNƒê - 3,000,000 VNƒê a month')\n",
      "('Innovature BPO', 'Data Analyst - Tableau', 'Th√†nh ph·ªë H·ªì Ch√≠ Minh', '2025-01-09 06:55:02', '24,000,000 VNƒê - 28,000,000 VNƒê a month')\n",
      "('C√¥ng ty TNHH Esuhai', 'Chuy√™n vi√™n ph√¢n t√≠ch d·ªØ li·ªáu - Data analyst', 'Th√†nh ph·ªë H·ªì Ch√≠ Minh', '2022-02-24 10:11:01', '')\n",
      "('wolf consulting', 'Data Analyst Intern', 'Th√†nh ph·ªë H·ªì Ch√≠ Minh', '2024-06-07 08:56:01', '')\n",
      "('C√¥ng TY TNHH Un - Available', 'Data Analytics Intern', 'Th√†nh ph·ªë H·ªì Ch√≠ Minh', '2025-01-04 13:41:52', '')\n",
      "('Heineken International B.V.', 'Data Analyst Intern', 'Th√†nh ph·ªë H·ªì Ch√≠ Minh', '2025-01-09 17:42:07', '')\n",
      "('VNG', 'Associate Data Analyst, Zalopay', 'Th√†nh ph·ªë H·ªì Ch√≠ Minh', '2024-08-19 10:03:21', '')\n",
      "('LEGO', 'Manufacturing Data Analyst', 'B√¨nh D∆∞∆°ng', '2025-01-07 07:27:56', '')\n",
      "('Concung.com', 'Data Analyst - Business Intelligence', 'Th√†nh ph·ªë H·ªì Ch√≠ Minh', '2024-12-23 22:12:48', '')\n",
      "('Avery Dennison', 'Data Analyst', 'Th√†nh ph·ªë H·ªì Ch√≠ Minh', '2023-11-17 22:17:22', '')\n",
      "('Customized Energy Solutions', 'Data Operations Analyst ‚Äì Retail Market Services - HCMC', 'Th√†nh ph·ªë H·ªì Ch√≠ Minh', '2024-10-19 14:42:04', '')\n",
      "('Wolf Solutions', 'Data Analyst Intern', 'Th√†nh ph·ªë H·ªì Ch√≠ Minh', '2022-09-30 07:49:39', '')\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T02:59:12.537811Z",
     "start_time": "2025-01-10T02:59:12.528854Z"
    }
   },
   "cell_type": "code",
   "source": "len(job_indeed_description_list)",
   "id": "a4390f179d839de4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T02:59:14.606255Z",
     "start_time": "2025-01-10T02:59:12.602810Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "from google.oauth2 import service_account\n",
    "import pandas as pd\n",
    "\n",
    "credentials = service_account.Credentials.from_service_account_file('credentials.json')\n",
    "spreadsheet_service = build('sheets', 'v4', credentials=credentials)\n",
    "\n",
    "SPREADSHEET_ID = '1F75bELM8_nYQvFBVqReVUZYcPGuuELIa4nh9MJoS9Tg'\n",
    "RANGE_NAME = 'Sheet1'\n",
    "sheet = spreadsheet_service.spreadsheets()\n",
    "result = sheet.values().get(spreadsheetId=SPREADSHEET_ID, range=RANGE_NAME).execute()\n",
    "values = result.get('values', [])\n",
    "max_cols = max(len(row) for row in values)\n",
    "values = [row + [''] * (max_cols - len(row)) for row in values]\n",
    "df = pd.DataFrame(values[1:], columns=values[0])\n",
    "df = df.fillna('')"
   ],
   "id": "aab379cf81ef9b1b",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T02:59:14.734403Z",
     "start_time": "2025-01-10T02:59:14.688769Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df1 = pd.DataFrame(job_indeed_description_list, columns=df.columns).__deepcopy__()\n",
    "df1"
   ],
   "id": "982272decfbf3da0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                 Link  \\\n",
       "0   https://vn.indeed.com/rc/clk?jk=c30b720dc8d6e0...   \n",
       "1   https://vn.indeed.com/rc/clk?jk=9224f9b085d181...   \n",
       "2   https://vn.indeed.com/rc/clk?jk=29ca84ee37db34...   \n",
       "3   https://vn.indeed.com/rc/clk?jk=ded399353790bb...   \n",
       "4   https://vn.indeed.com/rc/clk?jk=4ea7bd8035fc8d...   \n",
       "5   https://vn.indeed.com/rc/clk?jk=ef6e87670a5b5c...   \n",
       "6   https://vn.indeed.com/rc/clk?jk=c94f7b03b2a412...   \n",
       "7   https://vn.indeed.com/rc/clk?jk=b8592fed541177...   \n",
       "8   https://vn.indeed.com/rc/clk?jk=f7748be7f20ba6...   \n",
       "9   https://vn.indeed.com/rc/clk?jk=2f9bfb933381a3...   \n",
       "10  https://vn.indeed.com/rc/clk?jk=3e45f07d403c59...   \n",
       "11  https://vn.indeed.com/rc/clk?jk=0650c2efd27fc0...   \n",
       "12  https://vn.indeed.com/rc/clk?jk=c5a9ac5b18ff2a...   \n",
       "13  https://vn.indeed.com/rc/clk?jk=46f34aeca29608...   \n",
       "14  https://vn.indeed.com/rc/clk?jk=3178766f214cc3...   \n",
       "\n",
       "                                              Company  \\\n",
       "0                                     RMIT University   \n",
       "1                                         Bosch Group   \n",
       "2                                              VeXeRe   \n",
       "3   LARION Consulting & Software Development Joint...   \n",
       "4                                      Innovature BPO   \n",
       "5                                 C√¥ng ty TNHH Esuhai   \n",
       "6                                     wolf consulting   \n",
       "7                         C√¥ng TY TNHH Un - Available   \n",
       "8                         Heineken International B.V.   \n",
       "9                                                 VNG   \n",
       "10                                               LEGO   \n",
       "11                                        Concung.com   \n",
       "12                                     Avery Dennison   \n",
       "13                        Customized Energy Solutions   \n",
       "14                                     Wolf Solutions   \n",
       "\n",
       "                                                Title  \\\n",
       "0   Research and Data Analyst (short-term & contra...   \n",
       "1                            [SO] Senior Data Analyst   \n",
       "2                           HCM ‚Äì Data Analyst Intern   \n",
       "3                             Business Analyst Intern   \n",
       "4                              Data Analyst - Tableau   \n",
       "5        Chuy√™n vi√™n ph√¢n t√≠ch d·ªØ li·ªáu - Data analyst   \n",
       "6                                 Data Analyst Intern   \n",
       "7                               Data Analytics Intern   \n",
       "8                                 Data Analyst Intern   \n",
       "9                     Associate Data Analyst, Zalopay   \n",
       "10                         Manufacturing Data Analyst   \n",
       "11               Data Analyst - Business Intelligence   \n",
       "12                                       Data Analyst   \n",
       "13  Data Operations Analyst ‚Äì Retail Market Servic...   \n",
       "14                                Data Analyst Intern   \n",
       "\n",
       "                                     Salary               Location  \\\n",
       "0                                            Th√†nh ph·ªë H·ªì Ch√≠ Minh   \n",
       "1                                            Th√†nh ph·ªë H·ªì Ch√≠ Minh   \n",
       "2                                            Th√†nh ph·ªë H·ªì Ch√≠ Minh   \n",
       "3     1,000,000 VNƒê - 3,000,000 VNƒê a month  Th√†nh ph·ªë H·ªì Ch√≠ Minh   \n",
       "4   24,000,000 VNƒê - 28,000,000 VNƒê a month  Th√†nh ph·ªë H·ªì Ch√≠ Minh   \n",
       "5                                            Th√†nh ph·ªë H·ªì Ch√≠ Minh   \n",
       "6                                            Th√†nh ph·ªë H·ªì Ch√≠ Minh   \n",
       "7                                            Th√†nh ph·ªë H·ªì Ch√≠ Minh   \n",
       "8                                            Th√†nh ph·ªë H·ªì Ch√≠ Minh   \n",
       "9                                            Th√†nh ph·ªë H·ªì Ch√≠ Minh   \n",
       "10                                                      B√¨nh D∆∞∆°ng   \n",
       "11                                           Th√†nh ph·ªë H·ªì Ch√≠ Minh   \n",
       "12                                           Th√†nh ph·ªë H·ªì Ch√≠ Minh   \n",
       "13                                           Th√†nh ph·ªë H·ªì Ch√≠ Minh   \n",
       "14                                           Th√†nh ph·ªë H·ªì Ch√≠ Minh   \n",
       "\n",
       "            Date posted  \n",
       "0   2025-01-08 15:36:07  \n",
       "1   2025-01-08 03:27:59  \n",
       "2   2024-11-26 17:12:47  \n",
       "3   2024-11-14 07:28:53  \n",
       "4   2025-01-09 06:55:02  \n",
       "5   2022-02-24 10:11:01  \n",
       "6   2024-06-07 08:56:01  \n",
       "7   2025-01-04 13:41:52  \n",
       "8   2025-01-09 17:42:07  \n",
       "9   2024-08-19 10:03:21  \n",
       "10  2025-01-07 07:27:56  \n",
       "11  2024-12-23 22:12:48  \n",
       "12  2023-11-17 22:17:22  \n",
       "13  2024-10-19 14:42:04  \n",
       "14  2022-09-30 07:49:39  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Link</th>\n",
       "      <th>Company</th>\n",
       "      <th>Title</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Location</th>\n",
       "      <th>Date posted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://vn.indeed.com/rc/clk?jk=c30b720dc8d6e0...</td>\n",
       "      <td>RMIT University</td>\n",
       "      <td>Research and Data Analyst (short-term &amp; contra...</td>\n",
       "      <td></td>\n",
       "      <td>Th√†nh ph·ªë H·ªì Ch√≠ Minh</td>\n",
       "      <td>2025-01-08 15:36:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://vn.indeed.com/rc/clk?jk=9224f9b085d181...</td>\n",
       "      <td>Bosch Group</td>\n",
       "      <td>[SO] Senior Data Analyst</td>\n",
       "      <td></td>\n",
       "      <td>Th√†nh ph·ªë H·ªì Ch√≠ Minh</td>\n",
       "      <td>2025-01-08 03:27:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://vn.indeed.com/rc/clk?jk=29ca84ee37db34...</td>\n",
       "      <td>VeXeRe</td>\n",
       "      <td>HCM ‚Äì Data Analyst Intern</td>\n",
       "      <td></td>\n",
       "      <td>Th√†nh ph·ªë H·ªì Ch√≠ Minh</td>\n",
       "      <td>2024-11-26 17:12:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://vn.indeed.com/rc/clk?jk=ded399353790bb...</td>\n",
       "      <td>LARION Consulting &amp; Software Development Joint...</td>\n",
       "      <td>Business Analyst Intern</td>\n",
       "      <td>1,000,000 VNƒê - 3,000,000 VNƒê a month</td>\n",
       "      <td>Th√†nh ph·ªë H·ªì Ch√≠ Minh</td>\n",
       "      <td>2024-11-14 07:28:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://vn.indeed.com/rc/clk?jk=4ea7bd8035fc8d...</td>\n",
       "      <td>Innovature BPO</td>\n",
       "      <td>Data Analyst - Tableau</td>\n",
       "      <td>24,000,000 VNƒê - 28,000,000 VNƒê a month</td>\n",
       "      <td>Th√†nh ph·ªë H·ªì Ch√≠ Minh</td>\n",
       "      <td>2025-01-09 06:55:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://vn.indeed.com/rc/clk?jk=ef6e87670a5b5c...</td>\n",
       "      <td>C√¥ng ty TNHH Esuhai</td>\n",
       "      <td>Chuy√™n vi√™n ph√¢n t√≠ch d·ªØ li·ªáu - Data analyst</td>\n",
       "      <td></td>\n",
       "      <td>Th√†nh ph·ªë H·ªì Ch√≠ Minh</td>\n",
       "      <td>2022-02-24 10:11:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https://vn.indeed.com/rc/clk?jk=c94f7b03b2a412...</td>\n",
       "      <td>wolf consulting</td>\n",
       "      <td>Data Analyst Intern</td>\n",
       "      <td></td>\n",
       "      <td>Th√†nh ph·ªë H·ªì Ch√≠ Minh</td>\n",
       "      <td>2024-06-07 08:56:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>https://vn.indeed.com/rc/clk?jk=b8592fed541177...</td>\n",
       "      <td>C√¥ng TY TNHH Un - Available</td>\n",
       "      <td>Data Analytics Intern</td>\n",
       "      <td></td>\n",
       "      <td>Th√†nh ph·ªë H·ªì Ch√≠ Minh</td>\n",
       "      <td>2025-01-04 13:41:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>https://vn.indeed.com/rc/clk?jk=f7748be7f20ba6...</td>\n",
       "      <td>Heineken International B.V.</td>\n",
       "      <td>Data Analyst Intern</td>\n",
       "      <td></td>\n",
       "      <td>Th√†nh ph·ªë H·ªì Ch√≠ Minh</td>\n",
       "      <td>2025-01-09 17:42:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>https://vn.indeed.com/rc/clk?jk=2f9bfb933381a3...</td>\n",
       "      <td>VNG</td>\n",
       "      <td>Associate Data Analyst, Zalopay</td>\n",
       "      <td></td>\n",
       "      <td>Th√†nh ph·ªë H·ªì Ch√≠ Minh</td>\n",
       "      <td>2024-08-19 10:03:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>https://vn.indeed.com/rc/clk?jk=3e45f07d403c59...</td>\n",
       "      <td>LEGO</td>\n",
       "      <td>Manufacturing Data Analyst</td>\n",
       "      <td></td>\n",
       "      <td>B√¨nh D∆∞∆°ng</td>\n",
       "      <td>2025-01-07 07:27:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>https://vn.indeed.com/rc/clk?jk=0650c2efd27fc0...</td>\n",
       "      <td>Concung.com</td>\n",
       "      <td>Data Analyst - Business Intelligence</td>\n",
       "      <td></td>\n",
       "      <td>Th√†nh ph·ªë H·ªì Ch√≠ Minh</td>\n",
       "      <td>2024-12-23 22:12:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>https://vn.indeed.com/rc/clk?jk=c5a9ac5b18ff2a...</td>\n",
       "      <td>Avery Dennison</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td></td>\n",
       "      <td>Th√†nh ph·ªë H·ªì Ch√≠ Minh</td>\n",
       "      <td>2023-11-17 22:17:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>https://vn.indeed.com/rc/clk?jk=46f34aeca29608...</td>\n",
       "      <td>Customized Energy Solutions</td>\n",
       "      <td>Data Operations Analyst ‚Äì Retail Market Servic...</td>\n",
       "      <td></td>\n",
       "      <td>Th√†nh ph·ªë H·ªì Ch√≠ Minh</td>\n",
       "      <td>2024-10-19 14:42:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>https://vn.indeed.com/rc/clk?jk=3178766f214cc3...</td>\n",
       "      <td>Wolf Solutions</td>\n",
       "      <td>Data Analyst Intern</td>\n",
       "      <td></td>\n",
       "      <td>Th√†nh ph·ªë H·ªì Ch√≠ Minh</td>\n",
       "      <td>2022-09-30 07:49:39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T02:59:14.832324Z",
     "start_time": "2025-01-10T02:59:14.820696Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def implement_salary_filter():\n",
    "    global implement_filter_list\n",
    "    implement_filter_list = []\n",
    "    salary_filter_tuple = (salary_filter.split(' ')[0], salary_filter.split(' ')[1], salary_filter.split(' ')[2])\n",
    "    for index, row in df1.iterrows():\n",
    "        if op.contains(df1.at[index, 'Salary'], salary_filter_tuple[1]) and op.contains(df1.at[index, 'Salary'], salary_filter_tuple[2]):\n",
    "            range_salary_tuple = tuple(int(salary.replace(',', '')) for salary in re.findall(r\"([\\d,]+)\", df1.iloc[index]['Salary']))\n",
    "            print(range_salary_tuple)\n",
    "            if len(range_salary_tuple) == 2 and (int(salary_filter_tuple[0]) >= range_salary_tuple[0] and int(salary_filter_tuple[0]) <= range_salary_tuple[1]):\n",
    "                implement_filter_list.append((row[df1.columns[0]], row[df1.columns[1]], row[df1.columns[2]], row[df1.columns[3]], row[df1.columns[4]], row[df1.columns[5]]))\n",
    "                yield from implement_filter_list\n",
    "            elif len(range_salary_tuple) == 1 and (int(salary_filter_tuple[0]) <= range_salary_tuple[0] and op.contains(df1.iloc[index]['Salary'].lower(), 'up to')):\n",
    "                implement_filter_list.append((row[df1.columns[0]], row[df1.columns[1]], row[df1.columns[2]], row[df1.columns[3]], row[df1.columns[4]], row[df1.columns[5]]))\n",
    "                yield from implement_filter_list\n",
    "            elif len(range_salary_tuple) == 1 and (int(salary_filter_tuple[0]) >= range_salary_tuple[0] and op.contains(df1.iloc[index]['Salary'].lower(), 'from')):\n",
    "                implement_filter_list.append((row[df1.columns[0]], row[df1.columns[1]], row[df1.columns[2]], row[df1.columns[3]], row[df1.columns[4]], row[df1.columns[5]]))\n",
    "                yield from implement_filter_list\n",
    "            elif len(range_salary_tuple) == 1 and (int(salary_filter_tuple[0]) == range_salary_tuple[0] and (not op.contains(df1.iloc[index]['Salary'].lower(), 'up to') and not op.contains(df1.iloc[index]['Salary'].lower(), 'from'))):\n",
    "                implement_filter_list.append((row[df1.columns[0]], row[df1.columns[1]], row[df1.columns[2]], row[df1.columns[3]], row[df1.columns[4]], row[df1.columns[5]]))\n",
    "                yield from implement_filter_list\n",
    "salary_generators = implement_salary_filter()\n",
    "for generator in salary_generators:\n",
    "    print(generator)"
   ],
   "id": "2caa9b6698ede848",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T02:59:14.911240Z",
     "start_time": "2025-01-10T02:59:14.905919Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df2 = pd.DataFrame(implement_filter_list, columns=df1.columns).__deepcopy__()\n",
    "implement_filter_list = []"
   ],
   "id": "cfceb9999ab79def",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T02:59:14.948073Z",
     "start_time": "2025-01-10T02:59:14.942271Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def implement_date_posted_filter():\n",
    "    for row in df2.itertuples(index=False):\n",
    "        if pendulum.parse(start_date_posted_filter, tz='Asia/Ho_Chi_Minh') <= pendulum.parse(row._5, tz='Asia/Ho_Chi_Minh') and pendulum.parse(end_date_posted_filter, tz='Asia/Ho_Chi_Minh') >= pendulum.parse(row._5, tz='Asia/Ho_Chi_Minh'):\n",
    "            implement_filter_list.append((row.Link, row.Company, row.Title, row.Salary, row.Location, row._5))\n",
    "            yield from implement_filter_list\n",
    "date_posted_generators = implement_date_posted_filter()\n",
    "for generator in date_posted_generators:\n",
    "    print(generator)\n",
    "implement_filter_list = list(set(implement_filter_list))"
   ],
   "id": "2fff39bfbad0d0c1",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T02:59:15.437798Z",
     "start_time": "2025-01-10T02:59:14.996533Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df3 = pd.DataFrame(implement_filter_list, columns=df1.columns).__deepcopy__()\n",
    "updated_values = [df3.columns.tolist()] + df3.values.tolist()\n",
    "body = {'values': updated_values}\n",
    "spreadsheet_service.spreadsheets().values().update(\n",
    "    spreadsheetId=SPREADSHEET_ID, range=RANGE_NAME,\n",
    "    valueInputOption='RAW', body=body).execute()"
   ],
   "id": "ae3b56ab3a152dad",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'spreadsheetId': '1F75bELM8_nYQvFBVqReVUZYcPGuuELIa4nh9MJoS9Tg',\n",
       " 'updatedRange': 'Sheet1!A1:F1',\n",
       " 'updatedRows': 1,\n",
       " 'updatedColumns': 6,\n",
       " 'updatedCells': 6}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
